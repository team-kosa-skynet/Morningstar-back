package com.gaebang.backend.domain.newsData.service;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.gaebang.backend.domain.newsData.entity.NewsData;
import com.gaebang.backend.domain.newsData.event.NewsCreatedEvent;
import com.gaebang.backend.domain.newsData.repository.NewsDataRepository;
import com.gaebang.backend.domain.question.openai.util.OpenaiQuestionProperties;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.context.event.EventListener;
import org.springframework.scheduling.annotation.Async;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Propagation;
import org.springframework.transaction.annotation.Transactional;
import org.springframework.transaction.event.TransactionPhase;
import org.springframework.transaction.event.TransactionalEventListener;
import org.springframework.web.client.RestClient;

import java.time.LocalDateTime;
import java.util.*;

@Slf4j
@Service
@RequiredArgsConstructor
public class PopularNewsDataService {

    private final RestClient restClient;
    private final OpenaiQuestionProperties openaiQuestionProperties;
    private final NewsDataRepository newsDataRepository;
    private final NewsImageService newsImageService;

    // ë‰´ìŠ¤ ì „ì²´ ì¡°íšŒ í•œ ê²ƒ ê°€ê³µí•˜ê¸°
    public String getNewsData() {
        LocalDateTime now = LocalDateTime.now();
        LocalDateTime startOfYesterday = now.minusDays(1).toLocalDate().atStartOfDay();
        LocalDateTime endOfToday = now.toLocalDate().plusDays(1).atStartOfDay();

//        List<NewsData> newsData = newsDataRepository.findNewsByDateRange(startOfYesterday, endOfToday);
        List<NewsData> newsData = newsDataRepository.findTop40ByOrderByPubDateDesc();

        log.info("ë‰´ìŠ¤ ë°ì´í„° ê°œìˆ˜ í™•ì¸ ({}ë¶€í„° {}ê¹Œì§€): {}",
                startOfYesterday, endOfToday, newsData.size());

        StringBuilder data = new StringBuilder();
        data.append("[\n");

        for (int i = 0; i < newsData.size(); i++) {
            Long newsId = newsData.get(i).getNewsId();
            String title = escapeJsonString(newsData.get(i).getTitle());
            String description = escapeJsonString(newsData.get(i).getDescription());

            data.append(String.format("  {\n" +
                    "    \"newsId\": %d,\n" +
                    "    \"title\": \"%s\",\n" +
                    "    \"description\": \"%s\"\n" +
                    "  }", newsId, title, description));

            if (i < newsData.size() - 1) {
                data.append(",");
            }
            data.append("\n");
        }

        data.append("]");
        return data.toString();
    }

    // JSON ë¬¸ìì—´ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
    private String escapeJsonString(String input) {
        if (input == null) return "";
        return input.replace("\\", "\\\\")
                .replace("\"", "\\\"")
                .replace("\n", "\\n")
                .replace("\r", "\\r")
                .replace("\t", "\\t");
    }

    // content ì‘ì„±í•˜ê¸°
    private static String writeSystem() {
        return "SYSTEM: You are a news deduplication expert that identifies duplicate groups with STRICT criteria.\n" +
                "\n" +
                "!!! PRIMARY RULE (APPLY BEFORE ANYTHING ELSE) !!!\n" +
                "ONLY return groups that have 5 or MORE articles with 80%+ title+description similarity.\n" +
                "STRICTLY IGNORE any group with LESS than 5 articles â€” DO NOT include them in the output at all.\n" +
                "\n" +
                "TASK:\n" +
                "1. Compare title+description similarity (80%+ threshold)\n" +
                "2. Group articles with similarity >= 80%\n" +
                "3. A group qualifies as 'duplicate' ONLY if it has 5 or more articles\n" +
                "4. If no groups meet this, output empty duplicateGroups array\n" +
                "5. Include ALL articles in each valid group\n" +
                "6. For each group, find the earliest article by pubDate and include its newsId as earlyPubDateNewsId\n" +
                "\n" +
                "STRICT RULES:\n" +
                "- LESS than 5 articles â†’ IGNORE COMPLETELY\n" +
                "- DO NOT include small groups in the output\n" +
                "- This rule overrides all others\n" +
                "\n" +
                "OUTPUT FORMAT (VALID JSON ONLY):\n" +
                "{\n" +
                "  \"duplicateGroups\": [\n" +
                "    {\n" +
                "      \"groupId\": 1,\n" +
                "      \"articles\": [\n" +
                "        {\n" +
                "          \"newsId\": 123,\n" +
                "          \"title\": \"article title\",\n" +
                "          \"description\": \"article description\",\n" +
                "          \"pubDate\": \"article date\"\n" +
                "        }\n" +
                "      ],\n" +
                "      \"earlyPubDateNewsId\": 123\n" +
                "    }\n" +
                "  ]\n" +
                "}\n" +
                "\n" +
                "If no duplicates:\n" +
                "{\n" +
                "  \"duplicateGroups\": [],\n" +
                "  \"message\": \"ì¤‘ë³µ ê¸°ì‚¬ ì—†ìŒ\"\n" +
                "}\n" +
                "\n" +
                "CRITICAL:\n" +
                "- Output ONLY valid JSON\n" +
                "- No comments or explanations\n" +
                "- DO NOT list or mention groups under 5 articles\n" +
                "\n" +
                "INPUT: [news list]";
    }

    // ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ - ìˆœì°¨ ì‹¤í–‰
    @EventListener
    @TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT)
    @Async("taskExecutor")
    public void handleNewsCreated(NewsCreatedEvent event) {
        try {
            log.info("ë‰´ìŠ¤ ìƒì„± ì´ë²¤íŠ¸ ìˆ˜ì‹  - {}ê±´ì˜ ìƒˆ ë‰´ìŠ¤", event.getNewsCount());

            // 1. ì¤‘ë³µ ë¶„ì„ (ìš°ì„ )
            log.info("1ë‹¨ê³„: ì¤‘ë³µ ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘");
            getDuplatedNews();
            log.info("1ë‹¨ê³„: ì¤‘ë³µ ë‰´ìŠ¤ ë¶„ì„ ì™„ë£Œ");

            // 2. ì´ë¯¸ì§€ ìƒì„± (í›„ìˆœìœ„)
            log.info("2ë‹¨ê³„: ì´ë¯¸ì§€ ìƒì„± ì‹œì‘");
            newsImageService.createNewsImages();
            log.info("2ë‹¨ê³„: ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ");

        } catch (Exception e) {
            log.error("ë‰´ìŠ¤ í›„ì† ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜", e);
        }
    }

    // ì¤‘ë³µëœ ê¸°ì‚¬ ì°¾ê¸°
    @Transactional(propagation = Propagation.REQUIRES_NEW)
    public void getDuplatedNews() {
        try {
            log.info("=== ì¤‘ë³µ ë‰´ìŠ¤ íƒì§€ ì‹œì‘ ===");

            String modelToUse = openaiQuestionProperties.getDefaultModel();
            String openaiUrl = openaiQuestionProperties.getResponseUrl();
            log.info("ì‚¬ìš© ëª¨ë¸: {}, API URL: {}", modelToUse, openaiUrl);

            String promptSystem = writeSystem();
            String data = getNewsData();
            String content = promptSystem + "\n\nNews Data:\n" + data;

            log.info("ì „ì†¡í•  í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {} ë¬¸ì", content.length());

            // OpenAI API ìš”ì²­ êµ¬ì¡°
            Map<String, Object> message = new HashMap<>();
            message.put("role", "user");
            message.put("content", content);

            Map<String, Object> parameters = new HashMap<>();
            parameters.put("model", modelToUse);
            parameters.put("messages", Arrays.asList(message));
            parameters.put("max_tokens", 4000);
            parameters.put("temperature", 0);

            log.info("OpenAI API ìš”ì²­ íŒŒë¼ë¯¸í„°: {}", parameters.keySet());
            log.info("OpenAI API í˜¸ì¶œ ì‹œì‘...");

            String response = restClient.post()
                    .uri(openaiUrl)
                    .header("Authorization", "Bearer " + openaiQuestionProperties.getApiKey())
                    .header("Content-Type", "application/json")
                    .body(parameters)
                    .exchange((request, httpResponse) -> {
                        log.info("OpenAI API ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {}", httpResponse.getStatusCode());

                        if (Thread.currentThread().isInterrupted()) {
                            log.warn("OpenAI Chat Completions API ìŠ¤ë ˆë“œ ì¸í„°ëŸ½íŠ¸ ê°ì§€ - API í˜¸ì¶œ ì¤‘ë‹¨");
                            return null;
                        }

                        if (!httpResponse.getStatusCode().is2xxSuccessful()) {
                            log.error("OpenAI Chat Completions API í˜¸ì¶œ ì‹¤íŒ¨: {}", httpResponse.getStatusCode());
                            try {
                                String errorBody = new String(httpResponse.getBody().readAllBytes());
                                log.error("ì˜¤ë¥˜ ì‘ë‹µ ë³¸ë¬¸: {}", errorBody);
                            } catch (Exception e) {
                                log.error("ì˜¤ë¥˜ ì‘ë‹µ ì½ê¸° ì‹¤íŒ¨", e);
                            }
                            return null;
                        }

                        try {
                            String responseBody = new String(httpResponse.getBody().readAllBytes());
                            log.info("OpenAI API ì‘ë‹µ ê¸¸ì´: {} ë¬¸ì", responseBody.length());
                            return responseBody;
                        } catch (Exception e) {
                            log.error("ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜", e);
                            return null;
                        }
                    });

            if (response != null) {
                log.info("=== OpenAI API ì‘ë‹µ ì„±ê³µ ===");
                processDuplicateNews(response);
            } else {
                log.warn("=== OpenAI API ì‘ë‹µì´ null ===");
            }

            log.info("=== ì¤‘ë³µ ë‰´ìŠ¤ íƒì§€ ì™„ë£Œ ===");

        } catch (Exception e) {
            log.error("ì¤‘ë³µ ë‰´ìŠ¤ íƒì§€ ì¤‘ ì˜ˆì™¸ ë°œìƒ", e);
        }
    }

    // ì‘ë‹µ íŒŒì‹± ë©”ì„œë“œ
    private void processDuplicateNews(String response) {
        try {
            ObjectMapper objectMapper = new ObjectMapper();
            JsonNode rootNode = objectMapper.readTree(response);

            String contentJson = rootNode
                    .path("choices")
                    .get(0)
                    .path("message")
                    .path("content")
                    .asText();

            log.info("ì¶”ì¶œëœ content JSON: {}", contentJson);

            JsonNode contentNode = objectMapper.readTree(contentJson);
            JsonNode duplicateGroups = contentNode.path("duplicateGroups");

            for (JsonNode group : duplicateGroups) {
                int groupId = group.path("groupId").asInt();
                Long earlyPubDateNewsId = group.path("earlyPubDateNewsId").asLong();
                JsonNode articles = group.path("articles");

                log.info("=== ì¤‘ë³µ ê·¸ë£¹ {} ì²˜ë¦¬ ì‹œì‘ (ê¸°ì‚¬ {}ê°œ) ===", groupId, articles.size());
                log.info("  - ê°€ì¥ ë¨¼ì € ì‘ì„±ëœ ê¸°ì‚¬: newsId={}", earlyPubDateNewsId);

                List<Long> allNewsIds = new ArrayList<>();

                // ëª¨ë“  ê¸°ì‚¬ ì •ë³´ ìˆ˜ì§‘
                for (JsonNode article : articles) {
                    Long newsId = article.path("newsId").asLong();
                    String title = article.path("title").asText();
                    allNewsIds.add(newsId);

                    log.info("  - ì¤‘ë³µ ê¸°ì‚¬: newsId={}, title={}", newsId, title);
                }

                log.info("  - ê·¸ë£¹ ë‚´ ëª¨ë“  ê¸°ì‚¬: {}", allNewsIds);

                // DB ì—…ë°ì´íŠ¸ ë¡œì§
                if (earlyPubDateNewsId != null && allNewsIds.contains(earlyPubDateNewsId)) {

                    if (articles.size() >= 5) {
                        // 5ê°œ ì´ìƒ: ì¸ê¸°ê¸€ ì²˜ë¦¬ + ì¤‘ë³µê¸€ ë¹„í™œì„±í™”
                        log.info("  ğŸ“Š 5ê°œ ì´ìƒ ê·¸ë£¹ â†’ ì¸ê¸°ê¸€ ì²˜ë¦¬ + ì¤‘ë³µê¸€ ë¹„í™œì„±í™”");

                        // ê°€ì¥ ë¨¼ì € ì‘ì„±ëœ ê¸°ì‚¬ë¥¼ ì¸ê¸° ê¸°ì‚¬ë¡œ ì„¤ì •
                        newsDataRepository.markAsPopular(earlyPubDateNewsId);
                        log.info("  âœ… ì¸ê¸° ê¸°ì‚¬ë¡œ ì„¤ì •: newsId = {}", earlyPubDateNewsId);

                        // ë‚˜ë¨¸ì§€ ì¤‘ë³µ ê¸°ì‚¬ë“¤ì„ ë¹„í™œì„±í™”
                        for (Long newsId : allNewsIds) {
                            if (!newsId.equals(earlyPubDateNewsId)) {
                                newsDataRepository.markAsActive(newsId);
                                log.info("  âŒ ë¹„í™œì„±í™” ì²˜ë¦¬: newsId = {}", newsId);
                            }
                        }

                    } else {
                        // 5ê°œ ë¯¸ë§Œ: ì¸ê¸°ê¸€ ì²˜ë¦¬ ì•ˆí•¨ + ì¤‘ë³µê¸€ë§Œ ë¹„í™œì„±í™”
                        log.info("  ğŸ“ 5ê°œ ë¯¸ë§Œ ê·¸ë£¹ â†’ ì¤‘ë³µê¸€ë§Œ ë¹„í™œì„±í™” (ì¸ê¸°ê¸€ ì²˜ë¦¬ ì•ˆí•¨)");

                        // ì¸ê¸°ê¸€ ì²˜ë¦¬ëŠ” í•˜ì§€ ì•Šê³ , ì¤‘ë³µê¸€ë§Œ ë¹„í™œì„±í™”
                        for (Long newsId : allNewsIds) {
                            if (!newsId.equals(earlyPubDateNewsId)) {
                                newsDataRepository.markAsActive(newsId);
                                log.info("  âŒ ë¹„í™œì„±í™” ì²˜ë¦¬: newsId = {}", newsId);
                            }
                        }
                        log.info("  â„¹ï¸  ê°€ì¥ ë¨¼ì € ì‘ì„±ëœ ê¸°ì‚¬ ìœ ì§€ (ì¸ê¸°ê¸€ ì•„ë‹˜): newsId = {}", earlyPubDateNewsId);
                    }

                } else {
                    log.warn("  âš ï¸ earlyPubDateNewsIdë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŒ");
                }

                log.info("=== ì¤‘ë³µ ê·¸ë£¹ {} ì²˜ë¦¬ ì™„ë£Œ ===", groupId);
            }

            log.info("ì „ì²´ ì¤‘ë³µ ê¸°ì‚¬ ì²˜ë¦¬ ì™„ë£Œ: ì´ {}ê°œ ê·¸ë£¹ ì²˜ë¦¬", duplicateGroups.size());

        } catch (Exception e) {
            log.error("ì¤‘ë³µ ë‰´ìŠ¤ ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ", e);
        }
    }
}